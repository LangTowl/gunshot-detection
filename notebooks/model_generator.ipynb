{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T17:27:35.444196Z",
     "start_time": "2025-01-09T17:27:35.437702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import Input\n",
    "from keras import preprocessing\n",
    "from keras.src.utils import img_to_array\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "c4fb003e35793f16",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T17:27:35.455540Z",
     "start_time": "2025-01-09T17:27:35.452495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Paths to data\n",
    "gunshot_path = \"../data/processed/gunshot\"\n",
    "non_gunshot_path = \"../data/processed/not-gunshot\"\n",
    "\n",
    "# Verify that paths exists\n",
    "print(os.path.exists(gunshot_path))\n",
    "print(os.path.exists(non_gunshot_path))"
   ],
   "id": "ab1497560f0f8d7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T17:27:35.480794Z",
     "start_time": "2025-01-09T17:27:35.477703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to load and process images -> 0 for non-gunshot and 1 for gunshot\n",
    "def load_images(path, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "\n",
    "        # Only accept images\n",
    "        valid_extensions = ['.png', '.jpg', '.jpeg']\n",
    "        if not any(filename.lower().endswith(ext) for ext in valid_extensions):\n",
    "            continue\n",
    "\n",
    "        # Load local path to image\n",
    "        img_path = os.path.join(path, filename)\n",
    "\n",
    "        print(f\"Attempting to load image {img_path}\")\n",
    "\n",
    "        try:\n",
    "            # Resize to (128, 128) RGBA pixel image\n",
    "            img = preprocessing.image.load_img(img_path, target_size=(128, 128), color_mode=\"rgba\")\n",
    "\n",
    "            # Convert RGBA to RGB\n",
    "            img = img.convert(\"RGB\")\n",
    "\n",
    "            # Flatten into numpy array\n",
    "            img = img_to_array(img)\n",
    "\n",
    "            # Append image and corresponding label\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            continue\n",
    "\n",
    "    return images, labels"
   ],
   "id": "e19c15c4a44b711a",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T17:27:35.523575Z",
     "start_time": "2025-01-09T17:27:35.495993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load gunshots\n",
    "gunshot_images, gunshot_labels = load_images(gunshot_path, 1)\n",
    "non_gunshot_images, non_gunshot_labels = load_images(non_gunshot_path, 0)"
   ],
   "id": "ee4908874d90b558",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load image ../data/processed/gunshot/gunshot_4.png\n",
      "Attempting to load image ../data/processed/not-gunshot/gunshot_1.png\n",
      "Attempting to load image ../data/processed/not-gunshot/gunshot_2.png\n",
      "Attempting to load image ../data/processed/not-gunshot/gunshot_3.png\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T17:27:35.528202Z",
     "start_time": "2025-01-09T17:27:35.526050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Combine gunshots and labels of both types\n",
    "images = gunshot_images + non_gunshot_images\n",
    "labels = gunshot_labels + non_gunshot_labels\n",
    "\n",
    "# Convert them to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Normalize images\n",
    "images = images / 255.0"
   ],
   "id": "571ba21aad9fc3aa",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T17:27:35.545533Z",
     "start_time": "2025-01-09T17:27:35.542356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 20% for testing 80# for training\n",
    "# X_train -> training subset for input features (images)\n",
    "# X_val   -> validation subset for input features (images)\n",
    "# y_train -> training subset for labels\n",
    "# y_val   -> validation subset for labels\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ],
   "id": "736f1c8fbb48ef65",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T20:55:12.888461Z",
     "start_time": "2025-01-09T20:55:12.773360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the CNN model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Input layer to define the input shape\n",
    "# Output -> 3D Tensor shape (128, 128, 3) -> RGB image 128x128 pixels\n",
    "model.add(Input(shape=(128, 128, 3)))\n",
    "\n",
    "# Applies 32 convolution filters of dimension 3x3 to input\n",
    "# Output -> (126, 126, 32)\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# Reduces spatial dimensions by taking max value within overlapping 2x2 regions\n",
    "# Output -> (63, 63, 32)\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Applies 64 convolution filters of dimension 3x3 to input\n",
    "# Output -> (61, 61, 64)\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Reduces spatial dimensions by taking max value within overlapping 2x2 regions\n",
    "# Output -> (30, 30, 64)\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Applies 128 convolution filters of dimension 3x3 to input\n",
    "# Output -> (28, 28, 128)\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "# Reduces spatial dimensions by taking max value within overlapping 2x2 regions\n",
    "# Output -> (14, 14, 128)\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Converts 3D output from previous layer to 1D vector\n",
    "# Output -> (25088, )\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Applies 128 neurons to learn 'high level' features\n",
    "# Output -> (128, )\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "# Sigmoid function to determine gunshot or non-gunshot\n",
    "# 0 = non-gunshot, 1 = gunshot\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n"
   ],
   "id": "fcb00f2a2cd4c468",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T17:27:35.603288Z",
     "start_time": "2025-01-09T17:27:35.599006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compile the model:\n",
    "# Optimizer -> adam\n",
    "# loss function -> binary_crossentropy\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "id": "b69e88f947ee5e7a",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T17:27:36.880833Z",
     "start_time": "2025-01-09T17:27:35.610955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the model:\n",
    "# Epochs -> Total passes through model\n",
    "# Batch size -> # of samples the model processes before updating weights\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))"
   ],
   "id": "8bdd47e906779cbc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 696ms/step - accuracy: 0.3333 - loss: 0.7091 - val_accuracy: 1.0000 - val_loss: 0.0508\n",
      "Epoch 2/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 62ms/step - accuracy: 0.6667 - loss: 0.6371 - val_accuracy: 1.0000 - val_loss: 0.1483\n",
      "Epoch 3/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step - accuracy: 1.0000 - loss: 0.2497 - val_accuracy: 1.0000 - val_loss: 0.1486\n",
      "Epoch 4/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step - accuracy: 1.0000 - loss: 0.1798 - val_accuracy: 1.0000 - val_loss: 0.0666\n",
      "Epoch 5/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 55ms/step - accuracy: 1.0000 - loss: 0.0866 - val_accuracy: 1.0000 - val_loss: 0.0145\n",
      "Epoch 6/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 56ms/step - accuracy: 1.0000 - loss: 0.0294 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 7/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 58ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 1.0000 - val_loss: 1.5537e-04\n",
      "Epoch 8/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 56ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 1.2525e-05\n",
      "Epoch 9/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 63ms/step - accuracy: 1.0000 - loss: 2.3443e-04 - val_accuracy: 1.0000 - val_loss: 8.9496e-07\n",
      "Epoch 10/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 58ms/step - accuracy: 1.0000 - loss: 3.4405e-05 - val_accuracy: 1.0000 - val_loss: 5.8997e-08\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T17:27:36.929776Z",
     "start_time": "2025-01-09T17:27:36.888952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Determine performance metrics\n",
    "test_loss, test_acc = model.evaluate(X_val, y_val)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ],
   "id": "12874eda0d3e55e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 1.0000 - loss: 5.8997e-08\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T21:17:57.054052Z",
     "start_time": "2025-01-09T21:17:56.990881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save model\n",
    "model_name = \"test_model\"\n",
    "model.save(f'../models/{model_name}.h5')"
   ],
   "id": "ce72b190f1ccce25",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=../models/test_model.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[79], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Save model\u001B[39;00m\n\u001B[1;32m      2\u001B[0m model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_model\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 3\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../models/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mmodel_name\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/keras/src/saving/saving_api.py:114\u001B[0m, in \u001B[0;36msave_model\u001B[0;34m(model, filepath, overwrite, zipped, **kwargs)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(filepath)\u001B[38;5;241m.\u001B[39mendswith((\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.hdf5\u001B[39m\u001B[38;5;124m\"\u001B[39m)):\n\u001B[1;32m    111\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m legacy_h5_format\u001B[38;5;241m.\u001B[39msave_model_to_hdf5(\n\u001B[1;32m    112\u001B[0m         model, filepath, overwrite, include_optimizer\n\u001B[1;32m    113\u001B[0m     )\n\u001B[0;32m--> 114\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid filepath extension for saving. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    116\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease add either a `.keras` extension for the native Keras \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    117\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mformat (recommended) or a `.h5` extension. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    118\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUse `model.export(filepath)` if you want to export a SavedModel \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    119\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfor use with TFLite/TFServing/etc. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReceived: filepath=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilepath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    121\u001B[0m )\n",
      "\u001B[0;31mValueError\u001B[0m: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=../models/test_model."
     ]
    }
   ],
   "execution_count": 79
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
